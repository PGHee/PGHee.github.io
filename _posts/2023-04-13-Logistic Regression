---
layout: post
title:  "파이썬 로지스틱 회귀 "
published: true
---
파이썬을 이용한 로지스틱 회귀 분류기 튜토리얼
안녕하세요 친구들,

이 커널에서는 파이썬과 사이킷런을 사용하여 로지스틱 회귀를 구현합니다. 
오늘 오후에 오스트레일리아에서 비가 올지 여부를 예측하기 위해 로지스틱 회귀 분류기를 구축합니다. 
로지스틱 회귀를 사용하여 이진 분류 모델을 학습합니다.

1. 로지스틱 회귀 소개
데이터 과학자들이 새로운 분류 문제를 마주하게 되면, 가장 먼저 떠오르는 알고리즘은 로지스틱 회귀일 수 있습니다. 
로지스틱 회귀는 관측값을 이산적인 클래스 집합으로 예측하는 데 사용되는 지도 학습 분류 알고리즘입니다. 
실제로, 관측값을 다른 카테고리로 분류하는 데 사용됩니다. 따라서, 로지스틱 회귀의 출력은 이산적인 특성을 가집니다. 
로지스틱 회귀는 로짓 회귀(Logit Regression)로도 불립니다. 
분류 문제를 해결하기 위해 사용되는 가장 간단하고 직관적이며 다목적 분류 알고리즘 중 하나입니다.

2. 로지스틱 회귀 이해
통계학에서 로지스틱 회귀 모델은 주로 분류 목적으로 사용되는 널리 사용되는 통계 모델입니다. 
즉, 주어진 관측값 집합에 대해 로지스틱 회귀 알고리즘은 이러한 관측값을 두 개 이상의 이산적인 클래스로 분류하는 데 도움을 줍니다. 
따라서 대상 변수는 이산적인 특성을 가집니다.

로지스틱 회귀 알고리즘은 다음과 같이 작동합니다.

선형 방정식 구현하기
로지스틱 회귀 알고리즘은 독립 변수 또는 설명 변수로 선형 방정식을 구현하여 반응 값을 예측합니다. 
예를 들어, 우리는 공부한 시간과 시험 통과 확률의 예를 고려할 수 있습니다. 
여기서, 공부한 시간은 설명 변수이며 x1로 표시됩니다. 시험 통과 확률은 반응 또는 대상 변수이며 z로 표시됩니다.
설명 변수(x1)가 하나이고 반응 변수(z)가 하나인 경우, 선형 방정식은 다음 수식으로 수학적으로 표시됩니다.
z = β0 + β1x1
여기서, 계수 β0와 β1은 모델의 매개 변수입니다.
만약 설명 변수가 여러 개이면, 위의 방정식은 다음과 같이 확장될 수 있습니다.
z = β0 + β1x1+ β2x2+……..+ βnxn
여기서, 계수 β0, β1, β2 및 βn은 모델의 매개 변수입니다.
따라서 예측된 반응 값은 위의 방정식으로 주어지며 z로 표시됩니다.

시그모이드 함수
예측된 반응 값을 z로 표시하고, 이 값을 0과 1 사이의 확률 값으로 변환합니다. 
예측 값에서 확률 값으로 매핑하기 위해 시그모이드 함수를 사용합니다. 
이 시그모이드 함수는 어떤 실수 값을 0과 1 사이의 확률 값으로 매핑합니다.
머신 러닝에서는 시그모이드 함수를 사용하여 예측 값을 확률 값으로 매핑합니다. 
시그모이드 함수는 S 모양의 곡선을 가지며, sigmoid curve로도 불립니다.
시그모이드 함수는 로지스틱 함수의 특수한 경우입니다. 이는 다음 수학적 공식으로 나타낼 수 있습니다.
시각적으로, 시그모이드 함수는 다음 그래프로 나타낼 수 있습니다.
![Sigmoid Function](https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png)
