---
layout: post
title:  "파이썬 로지스틱 회귀 "
published: true
---
파이썬을 이용한 로지스틱 회귀 분류기 튜토리얼

이 커널에서는 파이썬과 사이킷런을 사용하여 로지스틱 회귀를 구현합니다. 
오늘 오후에 오스트레일리아에서 비가 올지 여부를 예측하기 위해 로지스틱 회귀 분류기를 구축합니다. 
로지스틱 회귀를 사용하여 이진 분류 모델을 학습합니다.

## 1. 로지스틱 회귀 소개

데이터 과학자들이 새로운 분류 문제를 마주하게 되면, 가장 먼저 떠오르는 알고리즘은 로지스틱 회귀일 수 있습니다. 로지스틱 회귀는 관측값을 이산적인 클래스 집합으로 예측하는 데 사용되는 지도 학습 분류 알고리즘입니다. 실제로, 관측값을 다른 카테고리로 분류하는 데 사용됩니다. 따라서, 로지스틱 회귀의 출력은 이산적인 특성을 가집니다. 로지스틱 회귀는 로짓 회귀(Logit Regression)로도 불립니다. 분류 문제를 해결하기 위해 사용되는 가장 간단하고 직관적이며 다목적 분류 알고리즘 중 하나입니다.

## 2. 로지스틱 회귀 이해

통계학에서 로지스틱 회귀 모델은 주로 분류 목적으로 사용되는 널리 사용되는 통계 모델입니다. 즉, 주어진 관측값 집합에 대해 로지스틱 회귀 알고리즘은 이러한 관측값을 두 개 이상의 이산적인 클래스로 분류하는 데 도움을 줍니다. 따라서 대상 변수는 이산적인 특성을 가집니다.

로지스틱 회귀 알고리즘은 다음과 같이 작동합니다.

선형 방정식 구현하기

로지스틱 회귀 알고리즘은 독립 변수 또는 설명 변수로 선형 방정식을 구현하여 반응 값을 예측합니다. 예를 들어, 우리는 공부한 시간과 시험 통과 확률의 예를 고려할 수 있습니다. 여기서, 공부한 시간은 설명 변수이며 x1로 표시됩니다. 시험 통과 확률은 반응 또는 대상 변수이며 z로 표시됩니다.설명 변수(x1)가 하나이고 반응 변수(z)가 하나인 경우, 선형 방정식은 다음 수식으로 수학적으로 표시됩니다.

z = β0 + β1x1

여기서, 계수 β0와 β1은 모델의 매개 변수입니다.
만약 설명 변수가 여러 개이면, 위의 방정식은 다음과 같이 확장될 수 있습니다.

z = β0 + β1x1+ β2x2+……..+ βnxn

여기서, 계수 β0, β1, β2 및 βn은 모델의 매개 변수입니다. 따라서 예측된 반응 값은 위의 방정식으로 주어지며 z로 표시됩니다.

시그모이드 함수

예측된 반응 값을 z로 표시하고, 이 값을 0과 1 사이의 확률 값으로 변환합니다. 예측 값에서 확률 값으로 매핑하기 위해 시그모이드 함수를 사용합니다. 이 시그모이드 함수는 어떤 실수 값을 0과 1 사이의 확률 값으로 매핑합니다.머신 러닝에서는 시그모이드 함수를 사용하여 예측 값을 확률 값으로 매핑합니다. 시그모이드 함수는 S 모양의 곡선을 가지며, sigmoid curve로도 불립니다.시그모이드 함수는 로지스틱 함수의 특수한 경우입니다. 이는 다음 수학적 공식으로 나타낼 수 있습니다.시각적으로, 시그모이드 함수는 다음 그래프로 나타낼 수 있습니다.

결정 경계

시그모이드 함수는 0과 1 사이의 확률 값을 반환합니다. 이 확률 값은 "0" 또는 "1"인 이산적인 클래스에 매핑됩니다. 이 이산적인 클래스로 확률 값을 매핑하기 위해 결정 경계라는 임계값을 선택합니다. 결정 경계 값 이상이면 확률 값을 클래스 1로 매핑하고, 결정 경계 값 미만이면 확률 값을 클래스 0으로 매핑합니다.

수학적으로 다음과 같이 표현할 수 있습니다:
p ≥ 0.5 => 클래스 = 1
p < 0.5 => 클래스 = 0
일반적으로, 결정 경계는 0.5로 설정됩니다. 
따라서 확률 값이 0.8 (> 0.5)인 경우, 이 관측치를 클래스 1로 매핑합니다. 
마찬가지로, 확률 값이 0.2 (< 0.5)인 경우, 이 관측치를 클래스 0으로 매핑합니다. 
이것은 아래 그래프에서 나타낼 수 있습니다.


이제, 로지스틱 회귀에서 시그모이드 함수와 결정 경계에 대해 알게 되었습니다. 시그모이드 함수와 결정 경계에 대한 지식을 사용하여 예측 함수를 작성할 수 있습니다. 로지스틱 회귀의 예측 함수는 관측치가 긍정적인 (Yes 또는 True)일 확률을 반환합니다. 이를 class 1로 표시하며, P(class = 1)로 표기합니다. 확률이 1에 가까워질수록 관측치가 class 1에 속할 가능성이 높아지며, 그렇지 않으면 class 0에 속합니다.

